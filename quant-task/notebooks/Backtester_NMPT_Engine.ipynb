{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Actor-Based Backtesting: Neo Modern Portfolio Theory (NMPT)\n",
                "\n",
                "This notebook implements **Neo Portfolio Management** using **Hierarchical Risk Parity (HRP)**. \n",
                "\n",
                "### Why NMPT? \n",
                "Standard MPT (Mean-Variance) is notoriously sensitive to parameter estimation errors (the 'Markowitz Optimization' instability). \n",
                "NMPT approaches like HRP use machine learning (Hierarchical Clustering) to build a diversified portfolio based on the correlation structure of assets, without requiring expected return estimates.\n",
                "\n",
                "### Strategy:\n",
                "- Use RSI, MACD, and SMA Golden Cross to identify signals.\n",
                "- Allocate capital using HRP among active signals."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from datetime import datetime, timedelta\n",
                "import uuid\n",
                "from sqlalchemy import create_engine, StaticPool\n",
                "from scipy.cluster.hierarchy import linkage\n",
                "from scipy.spatial.distance import squareform\n",
                "\n",
                "# 1. Setup Engine Paths\n",
                "engine_root = os.path.abspath(\"../another_testing_engine/trade-engine/trade-engine\")\n",
                "if engine_root not in sys.path:\n",
                "    sys.path.append(engine_root)\n",
                "\n",
                "from tradeengine.actors.memory import MemPortfolioActor\n",
                "from tradeengine.actors.sql import SQLOrderbookActor\n",
                "from tradeengine.backtest import BacktestStrategy\n",
                "from tradeengine.dto import Asset\n",
                "\n",
                "print(\"Engine components loaded.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## HRP Optimization Logic\n",
                "This implementation performs Quasi-Diagonalization and Recursive Bisection to allocate risk parity across clusters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_ivp(cov, **kargs):\n",
                "    ivp = 1. / np.diag(cov)\n",
                "    ivp /= ivp.sum()\n",
                "    return ivp\n",
                "\n",
                "def get_cluster_var(cov, c_items):\n",
                "    cov_ = cov.loc[c_items, c_items]\n",
                "    w_ = get_ivp(cov_)\n",
                "    c_var = np.dot(np.dot(w_, cov_), w_)\n",
                "    return c_var\n",
                "\n",
                "def get_quasi_diag(link):\n",
                "    link = link.astype(int)\n",
                "    sort_ix = pd.Series([link[-1, 0], link[-1, 1]])\n",
                "    num_items = link[-1, 3]\n",
                "    while sort_ix.max() >= num_items:\n",
                "        sort_ix.index = range(0, sort_ix.shape[0] * 2, 2)\n",
                "        df0 = sort_ix[sort_ix >= num_items]\n",
                "        i = df0.index\n",
                "        j = df0.values - num_items\n",
                "        sort_ix[i] = link[j, 0]\n",
                "        df0 = pd.Series(link[j, 1], index=i + 1)\n",
                "        sort_ix = pd.concat([sort_ix, df0])\n",
                "        sort_ix = sort_ix.sort_index()\n",
                "    return sort_ix.tolist()\n",
                "\n",
                "def get_rec_bisection(cov, sort_ix):\n",
                "    w = pd.Series(1, index=sort_ix)\n",
                "    c_items = [sort_ix]\n",
                "    while len(c_items) > 0:\n",
                "        c_items = [i[j:k] for i in c_items for j, k in ((0, len(i) // 2), (len(i) // 2, len(i))) if len(i) > 1]\n",
                "        for i in range(0, len(c_items), 2):\n",
                "            c_items0 = c_items[i]\n",
                "            c_items1 = c_items[i + 1]\n",
                "            v0 = get_cluster_var(cov, c_items0)\n",
                "            v1 = get_cluster_var(cov, c_items1)\n",
                "            alpha = 1 - v0 / (v0 + v1)\n",
                "            w[c_items0] *= alpha\n",
                "            w[c_items1] *= 1 - alpha\n",
                "    return w\n",
                "\n",
                "def optimize_hrp(returns):\n",
                "    corr = returns.corr()\n",
                "    cov = returns.cov()\n",
                "    dist = np.sqrt((1 - corr) / 2.)\n",
                "    link = linkage(squareform(dist), 'single')\n",
                "    sort_ix = get_quasi_diag(link)\n",
                "    sort_ix = corr.index[sort_ix].tolist()\n",
                "    hrp = get_rec_bisection(cov, sort_ix)\n",
                "    return hrp.to_dict()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Loading & Indicator Signals"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dir = \"../dataset/cleaned\"\n",
                "asset_files = sorted([f for f in os.listdir(data_dir) if f.startswith(\"Asset_\") and f.endswith(\".csv\")])[:30]\n",
                "assets = [f.split(\".\")[0] for f in asset_files]\n",
                "\n",
                "dfs = {}\n",
                "returns_list = {}\n",
                "for a, f in zip(assets, asset_files):\n",
                "    path = os.path.join(data_dir, f)\n",
                "    df = pd.read_csv(path, parse_dates=True, index_col=\"Date\").sort_index()\n",
                "    dfs[a] = df\n",
                "    returns_list[a] = df['Close'].pct_change()\n",
                "\n",
                "returns_df = pd.DataFrame(returns_list)\n",
                "\n",
                "def calculate_indicators(df):\n",
                "    df = df.copy()\n",
                "    delta = df['Close'].diff()\n",
                "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
                "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
                "    df['RSI'] = 100 - (100 / (1 + (gain/loss)))\n",
                "    df['MACD'] = df['Close'].ewm(span=12).mean() - df['Close'].ewm(span=26).mean()\n",
                "    df['Signal'] = df['MACD'].ewm(span=9).mean()\n",
                "    df['SMA50'] = df['Close'].rolling(50).mean()\n",
                "    df['SMA200'] = df['Close'].rolling(200).mean()\n",
                "    return df\n",
                "\n",
                "processed_dfs = {a: calculate_indicators(df) for a, df in dfs.items()}\n",
                "print(\"Indicators calculated.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Strategy Rebalancing with NMPT (HRP)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "active_assets = set()\n",
                "all_dates = sorted(returns_df.index)\n",
                "final_signals = {a: {} for a in assets}\n",
                "last_rebal = None\n",
                "\n",
                "for i, t in enumerate(all_dates):\n",
                "    changed = False\n",
                "    for a in assets:\n",
                "        if t not in processed_dfs[a].index: continue\n",
                "        row = processed_dfs[a].loc[t]\n",
                "        if (row['RSI'] > 70 or (row['SMA50'] < row['SMA200'] and row['MACD'] < row['Signal'])) and a in active_assets:\n",
                "            active_assets.remove(a)\n",
                "            final_signals[a][t] = {'CloseOrder': {}}\n",
                "            changed = True\n",
                "        elif (row['SMA50'] > row['SMA200'] or (row['RSI'] < 30 and row['MACD'] > row['Signal'])) and a not in active_assets:\n",
                "            if len(active_assets) < 15:\n",
                "                active_assets.add(a)\n",
                "                changed = True\n",
                "    \n",
                "    if (changed or (last_rebal is None or t.month != last_rebal.month)) and len(active_assets) > 2:\n",
                "        lookback = returns_df.loc[:t].tail(126)[list(active_assets)].dropna(how='all').fillna(0)\n",
                "        if len(lookback) > 20:\n",
                "            weights = optimize_hrp(lookback)\n",
                "            for a, w in weights.items():\n",
                "                final_signals[a][t] = {'TargetWeightOrder': {'size': float(w)}}\n",
                "            last_rebal = t\n",
                "\n",
                "formatted_signals = {a: pd.Series(sig).sort_index() for a, sig in final_signals.items()}\n",
                "print(\"NMPT signals generated.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Running NMPT Backtest"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "portfolio_actor = MemPortfolioActor.start(funding=1_000_000.0)\n",
                "db_engine = create_engine('sqlite://', connect_args={'check_same_thread': False}, poolclass=StaticPool)\n",
                "orderbook_actor = SQLOrderbookActor.start(portfolio_actor, db_engine, strategy_id=str(uuid.uuid4()))\n",
                "quote_frames = {a: dfs[a][['Open', 'High', 'Low', 'Close']] for a in assets}\n",
                "\n",
                "bt = BacktestStrategy(orderbook_actor, portfolio_actor, quote_frames)\n",
                "result = bt.run_backtest(formatted_signals)\n",
                "\n",
                "perf = result.porfolio_performance\n",
                "perf['performance'].plot(figsize=(12, 6), title=\"NMPT (Hierarchical Risk Parity) Performance\", color='purple')\n",
                "print(\"Total Return:\", (perf['performance'].iloc[-1] - 1) * 100, \"%\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "quant-task",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}